# BÃ¡o cÃ¡o Lab5 pháº§n 4: RNN for Named Entity Recognition (NER)

## MÃ´ táº£
BÃ i lab nÃ y xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh RNN (sá»­ dá»¥ng Bidirectional LSTM) Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n Nháº­n dáº¡ng Thá»±c thá»ƒ TÃªn (Named Entity Recognition) trÃªn bá»™ dá»¯ liá»‡u CoNLL 2003.

## Ná»™i dung Ä‘Ã£ thá»±c hiá»‡n

### Task 1: Táº£i vÃ  Tiá»n xá»­ lÃ½ Dá»¯ liá»‡u
- âœ… Táº£i dá»¯ liá»‡u CoNLL 2003 tá»« Hugging Face
- âœ… TrÃ­ch xuáº¥t cÃ¢u vÃ  nhÃ£n NER
- âœ… Chuyá»ƒn Ä‘á»•i nhÃ£n tá»« dáº¡ng sá»‘ sang string
- âœ… XÃ¢y dá»±ng tá»« Ä‘iá»ƒn `word_to_ix` vÃ  `tag_to_ix`

### Task 2: Táº¡o PyTorch Dataset vÃ  DataLoader
- âœ… Táº¡o class `NERDataset` káº¿ thá»«a tá»« `torch.utils.data.Dataset`
- âœ… Implement cÃ¡c phÆ°Æ¡ng thá»©c `__init__`, `__len__`, `__getitem__`
- âœ… Táº¡o `collate_fn` Ä‘á»ƒ padding cÃ¡c cÃ¢u trong batch
- âœ… Táº¡o DataLoader cho train, validation, vÃ  test sets

### Task 3: XÃ¢y dá»±ng MÃ´ hÃ¬nh RNN
- âœ… Táº¡o class `SimpleRNNForTokenClassification`
- âœ… Sá»­ dá»¥ng Bidirectional LSTM vá»›i 2 layers
- âœ… ThÃªm Embedding layer, Dropout, vÃ  Linear layer
- âœ… Tá»•ng sá»‘ parameters: ~2.7 triá»‡u parameters

### Task 4: Huáº¥n luyá»‡n MÃ´ hÃ¬nh
- âœ… Khá»Ÿi táº¡o `CrossEntropyLoss` vá»›i `ignore_index` cho padding
- âœ… Sá»­ dá»¥ng Adam optimizer vá»›i learning rate 0.001
- âœ… ThÃªm Learning Rate Scheduler (ReduceLROnPlateau)
- âœ… Implement training loop vá»›i 5 epochs
- âœ… Gradient clipping Ä‘á»ƒ trÃ¡nh exploding gradients
- âœ… Váº½ Ä‘á»“ thá»‹ loss theo epochs

### Task 5: ÄÃ¡nh giÃ¡ MÃ´ hÃ¬nh
- âœ… TÃ­nh token-level accuracy trÃªn validation set
- âœ… TÃ­nh F1-score chi tiáº¿t cho tá»«ng loáº¡i thá»±c thá»ƒ
- âœ… Táº¡o hÃ m `predict_sentence()` Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¢u má»›i
- âœ… Test vá»›i nhiá»u cÃ¢u vÃ­ dá»¥ khÃ¡c nhau

### Bonus
- âœ… LÆ°u vÃ  load mÃ´ hÃ¬nh vá»›i checkpoint Ä‘áº§y Ä‘á»§
- âœ… HÃ m `load_model()` Ä‘á»ƒ restore mÃ´ hÃ¬nh

## Kiáº¿n trÃºc MÃ´ hÃ¬nh

```
SimpleRNNForTokenClassification(
  (embedding): Embedding(21010, 100, padding_idx=0)
  (rnn): LSTM(100, 128, num_layers=2, batch_first=True, bidirectional=True)
  (fc): Linear(in_features=256, out_features=10, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
```

### ThÃ´ng sá»‘:
- **Vocab size**: 21,010 tá»«
- **Embedding dimension**: 100
- **Hidden dimension**: 128
- **Number of layers**: 2
- **Bidirectional**: Yes
- **Output classes**: 10 (sá»‘ lÆ°á»£ng nhÃ£n NER)
- **Dropout**: 0.3

## âš ï¸ LÆ°u Ã½ quan trá»ng vá» Dataset

**Váº¥n Ä‘á» vá»›i CoNLL 2003 dataset**:
Tá»« phiÃªn báº£n má»›i cá»§a thÆ° viá»‡n `datasets`, Hugging Face Ä‘Ã£ ngá»«ng há»— trá»£ dataset scripts. Notebook Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ tá»± Ä‘á»™ng thá»­ nhiá»u cÃ¡ch táº£i dataset:

1. Load trá»±c tiáº¿p tá»« `conll2003` (cÃ¡ch má»›i)
2. Load tá»« `eriktks/conll2003` (fork community)
3. Load tá»« revision cÅ©

Náº¿u váº«n gáº·p lá»—i, hÃ£y xem pháº§n Troubleshooting bÃªn dÆ°á»›i.

## CÃ¡ch cháº¡y

### 1. CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
```bash
pip install torch torchvision
pip install datasets
pip install transformers
pip install tqdm
pip install matplotlib
pip install scikit-learn
```

### 2. Cháº¡y notebook
```bash
jupyter notebook lab5_rnn_ner.ipynb
```
Hoáº·c má»Ÿ trong VS Code/Cursor vÃ  cháº¡y tá»«ng cell.

### 3. Huáº¥n luyá»‡n mÃ´ hÃ¬nh
Cháº¡y cÃ¡c cell theo thá»© tá»± tá»« trÃªn xuá»‘ng dÆ°á»›i. QuÃ¡ trÃ¬nh huáº¥n luyá»‡n sáº½:
- Táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u (~5 phÃºt)
- Huáº¥n luyá»‡n 5 epochs (~20-30 phÃºt trÃªn CPU, ~5-10 phÃºt trÃªn GPU)
- Tá»± Ä‘á»™ng lÆ°u best model vÃ o file `best_ner_model.pt`

### 4. Dá»± Ä‘oÃ¡n cÃ¢u má»›i
Sau khi huáº¥n luyá»‡n, báº¡n cÃ³ thá»ƒ dÃ¹ng hÃ m `predict_sentence()`:

```python
predict_sentence("VNU University is located in Hanoi", model, word_to_ix, ix_to_tag, device)
```

## Káº¿t quáº£ mong Ä‘á»£i

- **Validation Accuracy**: ~95-97%
- **F1-score**: ~0.85-0.90 (tÃ¹y loáº¡i entity)

### CÃ¡c nhÃ£n NER trong CoNLL 2003:
- `O`: Outside (khÃ´ng pháº£i entity)
- `B-PER`: Beginning of Person
- `I-PER`: Inside Person
- `B-ORG`: Beginning of Organization
- `I-ORG`: Inside Organization
- `B-LOC`: Beginning of Location
- `I-LOC`: Inside Location
- `B-MISC`: Beginning of Miscellaneous
- `I-MISC`: Inside Miscellaneous

## Files Ä‘Æ°á»£c táº¡o ra

Sau khi cháº¡y notebook, cÃ¡c file sau sáº½ Ä‘Æ°á»£c táº¡o:

1. `best_ner_model.pt` - Trá»ng sá»‘ cá»§a model tá»‘t nháº¥t
2. `ner_model_checkpoint.pt` - Checkpoint Ä‘áº§y Ä‘á»§ (bao gá»“m vocabularies vÃ  hyperparameters)

## VÃ­ dá»¥ Output

```
CÃ¢u: VNU University is located in Hanoi
======================================================================
Token                Predicted Tag       
----------------------------------------------------------------------
VNU                  B-ORG               
University           I-ORG               
is                   O                   
located              O                   
in                   O                   
Hanoi                B-LOC               
======================================================================
```

## ğŸ”§ Troubleshooting

### Váº¥n Ä‘á»: "RuntimeError: Dataset scripts are no longer supported"

**NguyÃªn nhÃ¢n**: Hugging Face Ä‘Ã£ ngá»«ng há»— trá»£ dataset scripts tá»« phiÃªn báº£n má»›i.

**Giáº£i phÃ¡p 1** (Khuyáº¿n nghá»‹): Sá»­ dá»¥ng dataset tá»« community
```python
dataset = load_dataset("eriktks/conll2003")
```

**Giáº£i phÃ¡p 2**: Downgrade thÆ° viá»‡n datasets
```bash
pip install datasets==2.14.0
```

**Giáº£i phÃ¡p 3**: Táº£i dataset thá»§ cÃ´ng
```python
# Táº£i tá»« URL trá»±c tiáº¿p
from datasets import load_from_disk
# ... (xem chi tiáº¿t trong notebook)
```

### Váº¥n Ä‘á»: Dataset táº£i quÃ¡ lÃ¢u

**Giáº£i phÃ¡p**: 
- Kiá»ƒm tra káº¿t ná»‘i internet
- Dataset khoáº£ng 80-100MB, cáº§n internet á»•n Ä‘á»‹nh
- Náº¿u bá»‹ giÃ¡n Ä‘oáº¡n, xÃ³a cache: `rm -rf ~/.cache/huggingface/datasets/conll2003*`

## Cáº£i tiáº¿n cÃ³ thá»ƒ thá»±c hiá»‡n

1. **Sá»­ dá»¥ng Pre-trained Embeddings**: GloVe, Word2Vec, FastText
2. **Thay Ä‘á»•i kiáº¿n trÃºc**: 
   - Thá»­ GRU thay vÃ¬ LSTM
   - TÄƒng sá»‘ layers
   - Thá»­ attention mechanism
3. **CRF Layer**: ThÃªm Conditional Random Field layer Ä‘á»ƒ cáº£i thiá»‡n dá»± Ä‘oÃ¡n
4. **Data Augmentation**: TÄƒng cÆ°á»ng dá»¯ liá»‡u
5. **Hyperparameter Tuning**: TÃ¬m learning rate, batch size tá»‘i Æ°u

## TÃ i liá»‡u tham kháº£o

- [CoNLL 2003 Dataset](https://huggingface.co/datasets/conll2003)
- [PyTorch LSTM Documentation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)
- [Named Entity Recognition Paper](https://arxiv.org/abs/1603.01360)

## License
Educational Use Only
